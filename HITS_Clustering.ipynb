{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pylab as plt\n",
    "import csv\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats import powerlaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('allgraph.csv', sep='\\t', header=None, encoding='utf-8', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = df.rename(columns={0:'KEYWORD',1:'POSITION',2:'SERP'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = {1:1,2:1,3:1,4:0.85,5:0.6,6:0.5,7:0.5,8:0.3,9:0.3,10:0.2,11:0.15,12:0.15,13:0.10,14:0.10,15:0.08,16:0.05,17:0.03,18:0.02,19:0.01,20:0.009}\n",
    "graph['POSITION'] = graph['POSITION'].replace(weight, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_k = set(graph['KEYWORD'])\n",
    "set_s = set(graph['SERP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authority = {}\n",
    "hub = {}\n",
    "\n",
    "for elem in set_k:\n",
    "    hub[elem] = 1\n",
    "    \n",
    "for elem in set_s:\n",
    "    authority[elem] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcolo score authority (influenzato dalla posizione della serp rispetto la keyword)\n",
    "\n",
    "for row in graph.itertuples(index=True, name='Pandas'):\n",
    "    serp = row.SERP\n",
    "    pos=row.POSITION\n",
    "    key = row.KEYWORD\n",
    "    authority[serp] = authority[serp] + pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcolo score hub (influenzato dallo score dell'authority a cui esso punta)\n",
    "\n",
    "for row in graph.itertuples(index=True, name='Pandas'):\n",
    "    serp = row.SERP\n",
    "    key = row.KEYWORD\n",
    "    hub[key] = hub[key] + authority[serp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizzazione dei vettori contenete i pesi per hub e authority. Dividendo i vettori, componente per componente, per la radice della sommatoria dei quadrati di\n",
    "#tutti i loro elementi cosÃ¬ che la loro somma dei quadrati sia unitaria\n",
    "\n",
    "tot_h = 0\n",
    "\n",
    "for key in hub.keys():\n",
    "    tot_h = tot_h + (hub[key]**2)\n",
    "    \n",
    "tot_h = math.sqrt(tot_h)\n",
    "\n",
    "for key in hub.keys():\n",
    "    hub[key] = \"%.8f\" % (hub[key]/tot_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_a = 0\n",
    "\n",
    "for key in authority.keys():\n",
    "    tot_a = tot_a + (authority[key]**2)\n",
    "\n",
    "tot_a = math.sqrt(tot_a)\n",
    "\n",
    "for key in authority.keys():\n",
    "    authority[key] = \"%.8f\" % (authority[key]/tot_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in authority.keys():\n",
    "    if(elem == 'lifegate.it'):\n",
    "        print(authority[elem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in hub.keys():\n",
    "    if(elem == 'spiedini'):\n",
    "        print(hub[elem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authority_max = max(authority.keys(), key=(lambda k: authority[k]))\n",
    "authority_min = min(authority.keys(), key=(lambda k: authority[k]))\n",
    "\n",
    "hub_max = max(hub.keys(), key=(lambda k: hub[k]))\n",
    "hub_min = min(hub.keys(), key=(lambda k: hub[k]))\n",
    "\n",
    "print(\"MAX AUTHORITY: \",authority_max,\"  HITS SCORE:\",authority[authority_max])\n",
    "print(\"MIN AUTHORITY: \",authority_min,\"  HITS SCORE:\",authority[authority_min])\n",
    "\n",
    "print(\"MAX HUB: \",hub_max,\"  HITS SCORE:\",hub[hub_max])\n",
    "print(\"MIN HUB: \",hub_min,\"  HITS SCORE:\",hub[hub_min])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=[]\n",
    "for elemen in authority.keys():\n",
    "    b=authority[elemen]\n",
    "    df.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myarray = np.asarray(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myarray= myarray.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#il grafico mostra la distribuzione dei pesi per le authority\n",
    "\n",
    "plt.plot(myarray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=sorted(myarray)\n",
    "fit = stats.norm.pdf(h, np.mean(h), np.std(h))  #this is a fitting indeed\n",
    "\n",
    "plt.plot(h,fit,'-o')\n",
    "\n",
    "plt.hist(h,normed=True)      #use this to draw histogram of your data\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#otteniamo il numero ottimale di bin applicando la regola di Sturge (1+(3.322*log(N)))\n",
    "\n",
    "nbin=1+3.322*(math.log(len(myarray)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbin=int(nbin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = range(1,72813)\n",
    "columns = ['auth']\n",
    "\n",
    "\n",
    "# Option 1: Set the column names in the structured array's dtype \n",
    "\n",
    "dtype = [('a','float32')]\n",
    "values = myarray\n",
    "df = pd.DataFrame(values, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viene aggiunta una colonna 'binned' per indicare il numero di bin a cui la serp appartiene\n",
    "\n",
    "df['binned'] = pd.cut(df[0], nbin,labels=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['binned'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['serps'] = set_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['binned'] == 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dizionario di dizionari\n",
    "#KEY: bin index   VALUE: Dizionario SERP,KEYWORDS\n",
    "index_serps = {}\n",
    "\n",
    "#Dizionario contenete l'intersezione delle keyword collegate a serp appartenenti allo stesso cluster\n",
    "#KEY: bin index   VALUE: Keywords intersection\n",
    "index_key_set = {}\n",
    "\n",
    "for i in range(2,39):\n",
    "    start_time = time.time()\n",
    "    if(not df.loc[df['binned'] == i].empty):\n",
    "        df_t = df.loc[df['binned'] == i]\n",
    "        key_serp = {}\n",
    "        list_key = []\n",
    "        for row in df_t.itertuples(index=True, name='Pandas'):\n",
    "            serp = row.serps\n",
    "            \n",
    "            #considera solo le keyword che si trovano nelle prime 5 posizioni per poter caratterizzare la serp relativa come top site\n",
    "            df_k = graph.loc[graph['SERP']== serp].loc[graph['POSITION'] >= 0.6] \n",
    "            \n",
    "            #lista contenente i set delle keyword per ogni set, utilizzata successivamente per ottenere l'intersezione\n",
    "            list_key.append(set(df_k['KEYWORD']))\n",
    "            key_serp[serp] = set(df_k['KEYWORD'])\n",
    "        \n",
    "        #per ogni bin i contiene la coppia serp,keywords\n",
    "        index_serps[i] = key_serp \n",
    "        \n",
    "        #contiene l'intersezione delle keyword relative al bin i\n",
    "        index_key_set[i] = set.intersection(*list_key) \n",
    "        \n",
    "    print(\"Iterazione \" , i ,\"  --- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(index_serps.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(index_serps.keys()):\n",
    "    print(\"BIN: \", i)\n",
    "    print(\"SERPS: \", list(index_serps[i].keys()))\n",
    "    print(\"N.KEYWORDS: \", len(index_key_set[i]))\n",
    "    print(\"-------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_key_set[38].intersection(index_key_set[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrive in diversi file csv la lista di keyword raggruppate per ogni bin\n",
    "\n",
    "for i in list(index_serps.keys()):\n",
    "    path =  \"Clusters/ListKeywordsForBin_\"\n",
    "    est = \".csv\"\n",
    "    csvFilename = (path+str(i)+est)  # what name you want to save your csv as\n",
    "    csv = open(csvFilename, \"w\", encoding = \"utf-8\")  # create or open csv, \"w\" to write strings\n",
    "    csv.write('')\n",
    "    for elem in index_key_set[i]:\n",
    "        csv.write(elem + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [4,7,8,10,11,13,16,17,19,25,29,38]  #non consideriamo 2,3,6 poichÃ¨ non possiedono keyword al loro interno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_113 = (\"buonissimo.org buttalapasta.it cucchiaio.it\")\n",
    "str_679 = (\"cookaround.com lacucinaitaliana.it giallozafferano.it salepepe.it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_key_index_113 = []\n",
    "lst_key_index_679 = []\n",
    "\n",
    "j = 0\n",
    "for elem in set_101113:\n",
    "    if(j<=15):\n",
    "        line = (str_113+\",\"+elem)\n",
    "        lst_key_index_113.append(line)\n",
    "        j = j+1\n",
    "\n",
    "k = 0\n",
    "for elem in set_161719:\n",
    "    if(k<=15):\n",
    "        line = (str_679+\",\"+elem)\n",
    "        lst_key_index_679.append(line)\n",
    "        k = k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv contenente l'intersezione tra le keyword appartenenti ai bin 10,11,13\n",
    "\n",
    "csvFilename = \"graphSample_113.csv\"\n",
    "csv = open(csvFilename, \"w\", encoding = \"utf-8\")  # create or open csv, \"w\" to write strings\n",
    "csv.write('')\n",
    "for elem in lst_key_index_113:\n",
    "        csv.write(elem + \"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv contenente l'intersezione tra le keyword appartenenti ai bin 16,17,19\n",
    "\n",
    "csvFilename = \"graphSample_679.csv\"\n",
    "csv = open(csvFilename, \"w\", encoding = \"utf-8\")  # create or open csv, \"w\" to write strings\n",
    "csv.write('')\n",
    "for elem in lst_key_index_679:\n",
    "        csv.write(elem + \"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dizionario serps / keywords\n",
    "#KEY: serps di ogni bin ottenuto  VALUE: keywords in comune tra le serp di ogni bin\n",
    "\n",
    "serps_conctn = {}\n",
    "for i in index:\n",
    "    serps_conctn[i] = \"\"\n",
    "    for elem in list(index_serps[i].keys()):\n",
    "        if(serps_conctn[i] == \"\"):\n",
    "            serps_conctn[i] = (elem+\" \")\n",
    "        else:\n",
    "            serps_conctn[i] = (serps_conctn[i]+elem+\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crea una lista serps,keywords al fine di realizzare un sample del grafo per la visualizzazione\n",
    "\n",
    "lst_key_index = []\n",
    "for i in index:\n",
    "    j = 0\n",
    "    for elem in index_key_set[i]:\n",
    "        if(j<=20):\n",
    "            line = (serps_conctn[i]+\",\"+elem)\n",
    "            lst_key_index.append(line)\n",
    "            j = j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFilename = \"graphSample.csv\"\n",
    "csv = open(csvFilename, \"w\", encoding = \"utf-8\")  # create or open csv, \"w\" to write strings\n",
    "csv.write('')\n",
    "for elem in lst_key_index:\n",
    "        csv.write(elem + \"\\n\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
